{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr1p-GeFqEOC"
      },
      "source": [
        "## Retrieval-Augmented Generative OpenAI Question Answering with OpenAI\n",
        "\n",
        "In my opinion, generative question answering is one of the most interesting applications of Large Language Models or LLMs. \n",
        "\n",
        "Generative question answering is a type of natural language processing (NLP) task where a model generates a natural language answer to a question based on a given context or passage.\n",
        "\n",
        "In this approach, the model generates the answer from scratch rather than selecting an answer from a pre-defined set of options. \n",
        "\n",
        "Ideally what I want to build is a chatbot that can answer my questions by extracting facts, drawing conclusions, or providing an insightful summary based on the most relevant text chunks extracted from the knowledge sources I put at its disposal. \n",
        "\n",
        "I can imagine this empathic bot to be a personal tutor for students in schools and universities, our educational system here in Egypt would benefit from such a bot, or a customer support agent, for example, if we are mobile phone operators and we want to allow our customers to send their inquiries 24/7 and find attentive support ready to answer them patiently.\n",
        "\n",
        "### Two Approaches with OpenAI\n",
        "Now, one approach to building such a bot is to fine-tune the selected LLM on text data covering the fine domain we want our model to be an expert in. But this approach has a number of issues:\n",
        "- Cost: Davinci model costs 0.02 USD per 1000 tokens (100 tokens ~= 75 words)\n",
        "- Cheaper and latest ```gpt-turbo-3.5``` model is not available yet for tuning\n",
        "- The model tends to be non-deterministic giving answers even when it is not sure or completely making answers up, aka hallucination.\n",
        "\n",
        "So rather than fine-tuning a model, we follow the more deterministic Semantic Search in + Text Generation approach. We divide the knoweldge base into chunks of text. We embed these chunks using ```text-embedding-ada-002``` model, then we provide text chunks we found relevant to our query to the latest and cost-effective ```gpt-turbo-3.5``` model to complete the text.\n",
        "\n",
        "**Because** we provided context information we stop the hallucinations, and the LLMs provide factual accurate answers. The OpenAI documentation says: \"If you provide the API with a body of text to answer questions about (like a Wikipedia entry) it will be less likely to confabulate a response.\" yet because of the generative text completion step we still get a human-like answer. \n",
        "\n",
        "**Also** with the answer we can give the source text our bot used to generate its reply, this would help the users to trust the system and \n",
        "confirm the reliability of the information presented to them. \n",
        "\n",
        "**And** we prime the model that to say \"I don't know\" for low-confidence answers.\n",
        "\n",
        "**Finally** as we said above this is cost-effective because we use ```gpt-3.5-turbo``` which performs at a similar capability to ```text-davinci-003``` but at 10% its price per token.\n",
        "\n",
        "## Limitations and Enhacements\n",
        "\n",
        "### Context Limitation\n",
        "Although this approach is appealing for its simplicity, it has a context size limitation. The maximum size prompt size is 4000 tokens which are approximately equal to 3000 words.\n",
        "\n",
        "So, adding context information to the prompt only works when the dataset of extra text that the model may need to know is small enough to fit in a single prompt. What do we do when we need the model to choose relevant contextual information from within a large body of information? and how context size limitation affects the quality of the answers this is still a question I need to look into.\n",
        "\n",
        "### Conversation History\n",
        "Another area that I may look into is prompt engineering to maintain the context across rounds of questions and answers by passing previous conversation history summaries in as part of the text completion API call. One elegant solution for this problem is what is done by the trending framework [LangChain](https://github.com/hwchase17/langchain).\n",
        "\n",
        "### Bot Persona\n",
        "Additionally, the API support \"persona\", which allows you to specify certain traits or characteristics of a fictional persona to add more context to the conversation. From [openai documentation](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb)\n",
        "\n",
        "I am here using a text version of Mark Twain's masterpiece Adventures of Tom Sawyer. Credit is to [gutenburg.org](gutenburg.org) project. I picked this book since it was one of my favorites in my childhood.\n",
        "\n",
        "In the remainder of this notebook, I will demonstrate a method for augmenting OpenAI ```gpt-3.5-turbo``` with a large body of additional contextual information by using document embeddings and retrieval. \n",
        "\n",
        "This method answers queries in two steps: \n",
        "\n",
        "**first** it retrieves the information relevant to the query, **then** it writes an answer tailored to the question based on the retrieved information. The first step uses the **Embeddings** API, and the second step uses the **Completions** API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao_wX6r7qEBh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grOz2m-brYOU",
        "outputId": "7024874c-82f4-4e90-abd3-d96c9e030803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (0.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.6.2)\n",
            "Requirement already satisfied: blobfile>=2 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.0.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (1.26.14)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (3.9.0)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (4.9.2)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (3.17)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "bmNzjAlOZP7h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1FoNYCxsqAms"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment - 1: No Context Provided"
      ],
      "metadata": {
        "id": "Us6aLTH6-zRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The System Prompt\n",
        "\n",
        "This prompt is what determines the entire behavior how the chatbot works, including its constraints and limitations which it *usually* follows. Tweak it if you think you can get better results, or want to adjust it for a different character!"
      ],
      "metadata": {
        "id": "1wFkakon-ZLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "system = \"\"\"\n",
        "You are a modern American literature tutor bot to help students with their study of Mark Twain's Adventures of Tom Sawyer. \n",
        "You are not an AI language model.\n",
        "You must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\n",
        "- ALWAYS REPLY IN FRIENDLY YET KNOWLEDGE TONE.\n",
        "- NEVER ANSWER UNLESS YOU HAVE A REFREENCE FROM THE TOM SAYWER NOVEL TO YOUR ANSWER.\n",
        "- IF YOU DON'T KNOW ANSWER 'I DO NOT KNOW'.\n",
        "Begin the conversation with a warm greetings, you may follow up with a quize question the readers knowledge of Mark Twain Tom Sawyer novel\n",
        "Refuse to talk about either race or gender. If asked about either race or gender, reply politly that you are designed to teach Mark Twain works only.\n",
        "If the user is stresseful or agressive, show understanding and empathy.\n",
        "At the end of the conversation, respond with \"<|DONE|>\".\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8ccVVY7vOCKy",
        "outputId": "9a6dbc3a-7c88-4531-f87a-143223849add"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! Tom met Huck Finn in the Adventures of Tom Sawyer when he was playing alone in the woods and stumbled upon Huck, who was also playing there. Huck was initially afraid of Tom, but they soon became friends and started to have many adventures together.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model"
      ],
      "metadata": {
        "id": "RMBthAm2-ktV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How did Tom meet Huck for the first time ?\"\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sFztsBcu-hRV",
        "outputId": "3062a5cb-8d06-4fb5-d6b9-f7f3a7c1082c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! In the novel \"The Adventures of Tom Sawyer,\" Tom met Huck Finn for the first time when he saw him in the street and threw a rock at him. Huck then chased Tom until Tom convinced him to stop by offering him a small amount of money. From that point on, they became friends and had many adventures together.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment - 2: Provide Relevant Context"
      ],
      "metadata": {
        "id": "yPgQSbsv_oUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data\n",
        "First we break up the document library into \"sections\" of context, which can be searched and retrieved separately.\n",
        "\n",
        "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the GPT-3 prompt. I found that approximately a 200 word section of text is a good length, but we should experiment for every particular use case."
      ],
      "metadata": {
        "id": "W4243p0A0G5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Open the file for reading\n",
        "with open(\"/content/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "\n",
        "    # Read the entire file into a string\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into chunks of 200 words\n",
        "words = text.split()\n",
        "paragraphs = [' '.join(words[i:i+200]) for i in range(0, len(words), 200)]\n",
        "\n",
        "# Convert paragraphs into a Pandas DataFrame\n",
        "df = pd.DataFrame({\"paragraphs\": paragraphs})\n"
      ],
      "metadata": {
        "id": "R1ayChRkg15w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.paragraphs[0:5]"
      ],
      "metadata": {
        "id": "PkMpaRzAsBoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7768ddbd-0f1e-4223-80ad-288376661b4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ﻿The Project Gutenberg eBook of The Adventures...\n",
              "1    CHAPTER VI. Self-Examination—Dentistry—The Mid...\n",
              "2    The Haunted House—Sleepy Ghosts—A Box of Gold—...\n",
              "3    Pinch-Bug Sid Dentistry Huckleberry Finn Mothe...\n",
              "4    the Prisoner Tom Swears The Court Room The Det...\n",
              "Name: paragraphs, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we overlap text chunks. This overlapping allow some repetions which helps to avoid losing valuable information relevant to the question because of the artficial dvisition of the text into fixed 200 long parts."
      ],
      "metadata": {
        "id": "FJd2Fb9DAfCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs_new = []\n",
        "window = 5  # number of segments to combine\n",
        "stride = 2  # number of segments to 'stride' over, used to create overlap\n",
        "for i in (range(0, len(paragraphs), stride)):\n",
        "    i_end = min(len(paragraphs)-1, i+window)\n",
        "    text = ' '.join(_ for _ in paragraphs[i:i_end])\n",
        "    paragraphs_new.append({\n",
        "        'text': text,\n",
        "    })"
      ],
      "metadata": {
        "id": "a8iXoRe3sLlR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs_new[0]"
      ],
      "metadata": {
        "id": "b0If6q5gsO6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209c95b4-2e47-43ce-a106-2ca3fe982b89"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '\\ufeffThe Project Gutenberg eBook of The Adventures of Tom Sawyer, by Mark Twain This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: The Adventures of Tom Sawyer Author: Mark Twain (Samuel Clemens) Release Date: July, 1993 [eBook #74] [Most recently updated: March 29, 2021] Language: English Character set encoding: UTF-8 Produced by: David Widger *** START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF TOM SAWYER *** THE ADVENTURES OF TOM SAWYER By Mark Twain (Samuel Langhorne Clemens) CONTENTS CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty—Tom Practices Music—The Challenge—A Private Entrance CHAPTER II. Strong Temptations—Strategic Movements—The Innocents Beguiled CHAPTER III. Tom as a General—Triumph and Reward—Dismal Felicity—Commission and Omission CHAPTER IV. Mental Acrobatics—Attending Sunday—School—The Superintendent—“Showing off”—Tom Lionized CHAPTER V. A Useful Minister—In Church—The Climax CHAPTER VI. Self-Examination—Dentistry—The Midnight Charm—Witches and Devils—Cautious Approaches—Happy Hours CHAPTER VII. A Treaty Entered Into—Early Lessons—A Mistake Made CHAPTER VIII. Tom Decides on his Course—Old Scenes Re-enacted CHAPTER IX. A Solemn Situation—Grave Subjects Introduced—Injun Joe Explains CHAPTER X. The Solemn Oath—Terror Brings Repentance—Mental Punishment CHAPTER XI. Muff Potter Comes Himself—Tom’s Conscience at Work CHAPTER XII. Tom Shows his Generosity—Aunt Polly Weakens CHAPTER XIII. The Young Pirates—Going to the Rendezvous—The Camp—Fire Talk CHAPTER XIV. Camp-Life—A Sensation—Tom Steals Away from Camp CHAPTER XV. Tom Reconnoiters—Learns the Situation—Reports at Camp CHAPTER XVI. A Day’s Amusements—Tom Reveals a Secret—The Pirates take a Lesson—A Night Surprise—An Indian War CHAPTER XVII. Memories of the Lost Heroes—The Point in Tom’s Secret CHAPTER XVIII. Tom’s Feelings Investigated—Wonderful Dream—Becky Thatcher Overshadowed—Tom Becomes Jealous—Black Revenge CHAPTER XIX. Tom Tells the Truth CHAPTER XX. Becky in a Dilemma—Tom’s Nobility Asserts Itself CHAPTER XXI. Youthful Eloquence—Compositions by the Young Ladies—A Lengthy Vision—The Boy’s Vengeance Satisfied CHAPTER XXII. Tom’s Confidence Betrayed—Expects Signal Punishment CHAPTER XXIII. Old Muff’s Friends—Muff Potter in Court—Muff Potter Saved CHAPTER XXIV. Tom as the Village Hero—Days of Splendor and Nights of Horror—Pursuit of Injun Joe CHAPTER XXV. About Kings and Diamonds—Search for the Treasure—Dead People and Ghosts CHAPTER XXVI. The Haunted House—Sleepy Ghosts—A Box of Gold—Bitter Luck CHAPTER XXVII. Doubts to be Settled—The Young Detectives CHAPTER XXVIII. An Attempt at No. Two—Huck Mounts Guard CHAPTER XXIX. The Pic-nic—Huck on Injun Joe’s Track—The “Revenge” Job—Aid for the Widow CHAPTER XXX. The Welshman Reports—Huck Under Fire—The Story Circulated —A New Sensation—Hope Giving Way to Despair CHAPTER XXXI. An Exploring Expedition—Trouble Commences—Lost in the Cave—Total Darkness—Found but not Saved CHAPTER XXXII. Tom tells the Story of their Escape—Tom’s Enemy in Safe Quarters CHAPTER XXXIII. The Fate of Injun Joe—Huck and Tom Compare Notes —An Expedition to the Cave—Protection Against Ghosts—“An Awful Snug Place”—A Reception at the Widow Douglas’s CHAPTER XXXIV. Springing a Secret—Mr. Jones’ Surprise a Failure CHAPTER XXXV. A New Order of Things—Poor Huck—New Adventures Planned ILLUSTRATIONS Tom Sawyer Tom at Home Aunt Polly Beguiled A Good Opportunity Who’s Afraid Late Home Jim ’Tendin’ to Business Ain’t that Work? Cat and Toys Amusement Becky Thatcher Paying Off After the Battle “Showing Off” Not Amiss Mary Tom Contemplating Dampened Ardor Youth Boyhood Using the “Barlow” The Church Necessities Tom as a Sunday-School Hero The Prize At Church The Model Boy The Church Choir A Side Show Result of Playing in Church The Pinch-Bug Sid Dentistry Huckleberry Finn Mother Hopkins Result of Tom’s Truthfulness Tom as an Artist Interrupted Courtship The Master Vain Pleading Tail Piece The Grave in the Woods Tom Meditates Robin Hood and his Foe Death of Robin Hood Midnight Tom’s Mode of Egress Tom’s Effort at Prayer Muff Potter Outwitted The Graveyard Forewarnings Disturbing Muff’s Sleep Tom’s Talk with his Aunt Muff Potter A Suspicious Incident Injun Joe’s two Victims In the Coils Peter Aunt Polly seeks Information A General Good Time Demoralized Joe Harper On Board Their First Prize The Pirates Ashore Wild Life The Pirate’s Bath The Pleasant Stroll The Search for the Drowned The Mysterious Writing River View What Tom Saw Tom Swims the River Taking Lessons The Pirates’ Egg Market Tom Looking for Joe’s Knife The Thunder Storm Terrible Slaughter The Mourner Tom’s Proudest Moment Amy Lawrence Tom tries to Remember The Hero A Flirtation Becky Retaliates A Sudden Frost Counter-irritation Aunt Polly Tom justified The Discovery Caught in the Act Tom Astonishes the School Literature Tom Declaims Examination Evening On Exhibition Prize Authors The Master’s Dilemma The School House The Cadet Happy for Two Days Enjoying the Vacation The Stolen Melons The Judge Visiting the Prisoner Tom Swears The Court Room The Detective Tom Dreams The Treasure The Private Conference A King; Poor Fellow! Business The Ha’nted House Injun Joe The Greatest and Best Hidden Treasures Unearthed The Boy’s Salvation Room No. 2 The Next Day’s Conference Treasures Uncle Jake Buck at Home The Haunted Room “Run for Your Life” McDougal’s Cave Inside the Cave Huck on Duty A Rousing Act Tail Piece The Welshman Result of a Sneeze Cornered Alarming Discoveries Tom and Becky stir up the Town Tom’s Marks Huck Questions the Widow Vampires Wonders of the Cave Attacked by Natives Despair The Wedding Cake A New Terror Daylight “Turn Out” to Receive Tom and Becky The Escape from the Cave Fate of the Ragged Man The Treasures Found Caught at Last Drop after Drop Having a Good Time A Business Trip “Got it at Last!” Tail Piece Widow Douglas Tom Backs his Statement Tail Piece Huck Transformed Comfortable Once More High up in Society Contentment PREFACE Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. Huck Finn is drawn from life; Tom'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar are their contents. \n"
      ],
      "metadata": {
        "id": "FFGD_KxeBuvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n"
      ],
      "metadata": {
        "id": "U6mwPVl7sTmQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding model parameters\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
        "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
      ],
      "metadata": {
        "id": "APPUOeXEsXjf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "# should print [83, 1609, 5963, 374, 2294, 0]\n",
        "encoding.encode(\"tiktoken is great!\")"
      ],
      "metadata": {
        "id": "Blhk06rUsb4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59ba83b-10e6-40e8-b342-cf9d235fcf21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[83, 1609, 5963, 374, 2294, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(paragraphs_new)\n",
        "# noteiced a row with empty text, removing that\n",
        "df=df[df.text.ne('')]\n",
        "# encode , I might not need this step\n",
        "df[\"n_tokens\"] = df.text.apply(lambda x: len(encoding.encode(str(x))))\n",
        "# filter too long text if any\n",
        "df = df[df.n_tokens <= max_tokens]\n",
        "df"
      ],
      "metadata": {
        "id": "QdiSaxp8sgyQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8335cae2-6cda-4651-9193-976a147b0353"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  n_tokens\n",
              "0    ﻿The Project Gutenberg eBook of The Adventures...      1577\n",
              "1    The Haunted House—Sleepy Ghosts—A Box of Gold—...      1370\n",
              "2    the Prisoner Tom Swears The Court Room The Det...      1281\n",
              "3    have seen through a pair of stove-lids just as...      1326\n",
              "4    and spile the child, as the Good Book says. I’...      1324\n",
              "..                                                 ...       ...\n",
              "180  1.E.9. 1.E.3. If an individual Project Gutenbe...      1273\n",
              "181  tax returns. Royalty payments should be clearl...      1248\n",
              "182  EXCEPT THOSE PROVIDED IN PARAGRAPH 1.F.3. YOU ...      1237\n",
              "183  or deletions to any Project Gutenberg-tm work,...       733\n",
              "184  not received written confirmation of complianc...       244\n",
              "\n",
              "[185 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d685a1d-42fc-4a5f-9faa-726ce4e20a0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>﻿The Project Gutenberg eBook of The Adventures...</td>\n",
              "      <td>1577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Haunted House—Sleepy Ghosts—A Box of Gold—...</td>\n",
              "      <td>1370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Prisoner Tom Swears The Court Room The Det...</td>\n",
              "      <td>1281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have seen through a pair of stove-lids just as...</td>\n",
              "      <td>1326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and spile the child, as the Good Book says. I’...</td>\n",
              "      <td>1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>1.E.9. 1.E.3. If an individual Project Gutenbe...</td>\n",
              "      <td>1273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>tax returns. Royalty payments should be clearl...</td>\n",
              "      <td>1248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>EXCEPT THOSE PROVIDED IN PARAGRAPH 1.F.3. YOU ...</td>\n",
              "      <td>1237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>or deletions to any Project Gutenberg-tm work,...</td>\n",
              "      <td>733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>not received written confirmation of complianc...</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>185 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d685a1d-42fc-4a5f-9faa-726ce4e20a0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d685a1d-42fc-4a5f-9faa-726ce4e20a0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d685a1d-42fc-4a5f-9faa-726ce4e20a0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"embedding\"] = df.text.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
        "df[0:5]"
      ],
      "metadata": {
        "id": "KWe3unLrslSA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f2b1e908-5048-4275-dc45-dbeb7db866b2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  n_tokens  \\\n",
              "0  ﻿The Project Gutenberg eBook of The Adventures...      1577   \n",
              "1  The Haunted House—Sleepy Ghosts—A Box of Gold—...      1370   \n",
              "2  the Prisoner Tom Swears The Court Room The Det...      1281   \n",
              "3  have seen through a pair of stove-lids just as...      1326   \n",
              "4  and spile the child, as the Good Book says. I’...      1324   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.001815861207433045, -0.019039329141378403, ...  \n",
              "1  [-0.0031101375352591276, -0.007375660818070173...  \n",
              "2  [-0.01737176440656185, -0.010609232820570469, ...  \n",
              "3  [-0.001428895047865808, -0.017115658149123192,...  \n",
              "4  [-0.0015302413376048207, -0.004893323872238398...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12bd82d6-3480-4b76-8ecf-588eb65610b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>﻿The Project Gutenberg eBook of The Adventures...</td>\n",
              "      <td>1577</td>\n",
              "      <td>[0.001815861207433045, -0.019039329141378403, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Haunted House—Sleepy Ghosts—A Box of Gold—...</td>\n",
              "      <td>1370</td>\n",
              "      <td>[-0.0031101375352591276, -0.007375660818070173...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Prisoner Tom Swears The Court Room The Det...</td>\n",
              "      <td>1281</td>\n",
              "      <td>[-0.01737176440656185, -0.010609232820570469, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have seen through a pair of stove-lids just as...</td>\n",
              "      <td>1326</td>\n",
              "      <td>[-0.001428895047865808, -0.017115658149123192,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and spile the child, as the Good Book says. I’...</td>\n",
              "      <td>1324</td>\n",
              "      <td>[-0.0015302413376048207, -0.004893323872238398...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12bd82d6-3480-4b76-8ecf-588eb65610b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12bd82d6-3480-4b76-8ecf-588eb65610b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12bd82d6-3480-4b76-8ecf-588eb65610b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"embedding\"] = df.embedding.apply(np.array)\n",
        "df[0:5]"
      ],
      "metadata": {
        "id": "sfeYVXh7sqxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "59aa4c05-ee6c-4878-e5ff-47a492facf3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  n_tokens  \\\n",
              "0  ﻿The Project Gutenberg eBook of The Adventures...      1577   \n",
              "1  The Haunted House—Sleepy Ghosts—A Box of Gold—...      1370   \n",
              "2  the Prisoner Tom Swears The Court Room The Det...      1281   \n",
              "3  have seen through a pair of stove-lids just as...      1326   \n",
              "4  and spile the child, as the Good Book says. I’...      1324   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.001815861207433045, -0.019039329141378403, ...  \n",
              "1  [-0.0031101375352591276, -0.007375660818070173...  \n",
              "2  [-0.01737176440656185, -0.010609232820570469, ...  \n",
              "3  [-0.001428895047865808, -0.017115658149123192,...  \n",
              "4  [-0.0015302413376048207, -0.004893323872238398...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-168dc85b-a116-42f2-b6f6-7b3360941624\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>﻿The Project Gutenberg eBook of The Adventures...</td>\n",
              "      <td>1577</td>\n",
              "      <td>[0.001815861207433045, -0.019039329141378403, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Haunted House—Sleepy Ghosts—A Box of Gold—...</td>\n",
              "      <td>1370</td>\n",
              "      <td>[-0.0031101375352591276, -0.007375660818070173...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Prisoner Tom Swears The Court Room The Det...</td>\n",
              "      <td>1281</td>\n",
              "      <td>[-0.01737176440656185, -0.010609232820570469, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>have seen through a pair of stove-lids just as...</td>\n",
              "      <td>1326</td>\n",
              "      <td>[-0.001428895047865808, -0.017115658149123192,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and spile the child, as the Good Book says. I’...</td>\n",
              "      <td>1324</td>\n",
              "      <td>[-0.0015302413376048207, -0.004893323872238398...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-168dc85b-a116-42f2-b6f6-7b3360941624')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-168dc85b-a116-42f2-b6f6-7b3360941624 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-168dc85b-a116-42f2-b6f6-7b3360941624');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/the_adventures_of_tom_sawyer.csv')"
      ],
      "metadata": {
        "id": "_EG3GdBW8-YC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embed The Query"
      ],
      "metadata": {
        "id": "_3jLplz2DPZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How did Tom meet Huck for the first time ?\"\n",
        "prompt_embedding = get_embedding(prompt, engine=embedding_model)\n",
        "prompt_embedding"
      ],
      "metadata": {
        "id": "PSJt7wE_suIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b268ab63-c8e5-472a-e016-3272adde958f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.005511189345270395,\n",
              " -0.025657134130597115,\n",
              " -0.003149250987917185,\n",
              " -0.017638452351093292,\n",
              " -0.013364468701183796,\n",
              " 0.04104612022638321,\n",
              " 0.012663165107369423,\n",
              " 0.010823896154761314,\n",
              " -0.007773886434733868,\n",
              " -0.024876436218619347,\n",
              " 0.01972913183271885,\n",
              " 0.018392683938145638,\n",
              " -0.0022792373783886433,\n",
              " -0.008468573912978172,\n",
              " 0.0003963441704399884,\n",
              " 0.006023935042321682,\n",
              " 0.01642109453678131,\n",
              " 0.008250243961811066,\n",
              " 0.004326912108808756,\n",
              " -0.03493287041783333,\n",
              " -0.010909905657172203,\n",
              " 0.00327661051414907,\n",
              " 0.01659311354160309,\n",
              " -0.0003824917657766491,\n",
              " -0.019755596294999123,\n",
              " 0.014965558424592018,\n",
              " 0.02408250793814659,\n",
              " -0.01593150570988655,\n",
              " 0.026345204561948776,\n",
              " -0.013258611783385277,\n",
              " 0.000781110196840018,\n",
              " -0.0011429267469793558,\n",
              " -0.01992761343717575,\n",
              " -0.0036619966849684715,\n",
              " -0.019940845668315887,\n",
              " -0.003387429751455784,\n",
              " -0.007535708136856556,\n",
              " 0.005335863213986158,\n",
              " 0.020800935104489326,\n",
              " -0.014886165969073772,\n",
              " -0.008012065663933754,\n",
              " -0.008713369257748127,\n",
              " -0.009202958084642887,\n",
              " -0.0292165819555521,\n",
              " -0.035118117928504944,\n",
              " 0.012907959520816803,\n",
              " -0.015415451489388943,\n",
              " -0.00866044033318758,\n",
              " -0.0018276904011145234,\n",
              " -0.0008373468299396336,\n",
              " 0.019861454144120216,\n",
              " 0.022812221199274063,\n",
              " -4.458096555026714e-06,\n",
              " -0.010056432336568832,\n",
              " -0.010036583989858627,\n",
              " 0.0019980543293058872,\n",
              " -0.009613155387341976,\n",
              " 0.02053629234433174,\n",
              " -0.004667640198022127,\n",
              " 0.008686904795467854,\n",
              " 0.005845301318913698,\n",
              " 0.022507883608341217,\n",
              " 0.01712239906191826,\n",
              " -0.006556529086083174,\n",
              " -0.019715899601578712,\n",
              " -0.0008129500783979893,\n",
              " -0.008005449548363686,\n",
              " -0.02580268681049347,\n",
              " -0.0226269718259573,\n",
              " 0.005914770066738129,\n",
              " 0.007224752567708492,\n",
              " 0.019107220694422722,\n",
              " 0.009097101166844368,\n",
              " -0.008448726497590542,\n",
              " 0.02608056180179119,\n",
              " 0.024122204631567,\n",
              " -0.022798990830779076,\n",
              " -0.018472077324986458,\n",
              " -0.019490953534841537,\n",
              " 0.01230589672923088,\n",
              " -0.00015981952310539782,\n",
              " -0.019715899601578712,\n",
              " -0.01335123647004366,\n",
              " 0.04985873028635979,\n",
              " 0.021833043545484543,\n",
              " -0.008151003159582615,\n",
              " -0.007363690063357353,\n",
              " 0.033477332442998886,\n",
              " -0.029163653030991554,\n",
              " -0.007535708136856556,\n",
              " 0.004839657805860043,\n",
              " 0.03810858353972435,\n",
              " -0.004012648481875658,\n",
              " 0.015997666865587234,\n",
              " 0.004670948255807161,\n",
              " -0.0026596616953611374,\n",
              " -0.03064565360546112,\n",
              " 0.026477526873350143,\n",
              " 0.00916987843811512,\n",
              " -0.03350379690527916,\n",
              " -0.018167737871408463,\n",
              " 0.022957775741815567,\n",
              " -0.023619383573532104,\n",
              " -0.01188246812671423,\n",
              " -0.03273633122444153,\n",
              " -0.010665111243724823,\n",
              " 0.017069470137357712,\n",
              " -0.004598170984536409,\n",
              " 0.007218136452138424,\n",
              " -0.019504185765981674,\n",
              " 0.011035610921680927,\n",
              " 0.01871025562286377,\n",
              " -0.0007703590672463179,\n",
              " -0.027602259069681168,\n",
              " -0.022521113976836205,\n",
              " -0.025458650663495064,\n",
              " 0.00959992315620184,\n",
              " -0.03916715458035469,\n",
              " -0.00183430640026927,\n",
              " -0.0055575016885995865,\n",
              " 0.010440164245665073,\n",
              " 0.034456510096788406,\n",
              " 0.013463709503412247,\n",
              " -0.005398716311901808,\n",
              " -0.001303366501815617,\n",
              " 0.01192216482013464,\n",
              " -0.029560618102550507,\n",
              " 0.009719012305140495,\n",
              " 0.009116949513554573,\n",
              " 0.0033328470308333635,\n",
              " 0.054516445845365524,\n",
              " 0.023857561871409416,\n",
              " 0.014740612357854843,\n",
              " -0.012729325331747532,\n",
              " -0.02200506068766117,\n",
              " 0.039352405816316605,\n",
              " -0.036044370383024216,\n",
              " -7.541289960499853e-05,\n",
              " -0.033927224576473236,\n",
              " -0.03215411677956581,\n",
              " 0.013357852585613728,\n",
              " 0.004634559620171785,\n",
              " 0.009619771502912045,\n",
              " -0.0009973731357604265,\n",
              " 0.008633975870907307,\n",
              " 0.029190117493271828,\n",
              " 0.046074338257312775,\n",
              " 0.00314263510517776,\n",
              " 0.01084374450147152,\n",
              " -0.006440747529268265,\n",
              " 0.024757348001003265,\n",
              " -0.0032269898802042007,\n",
              " -0.014542129822075367,\n",
              " 0.012941040098667145,\n",
              " 0.006109944079071283,\n",
              " 0.00249591376632452,\n",
              " 0.002022864529863,\n",
              " -0.0061926450580358505,\n",
              " 0.006199261173605919,\n",
              " 0.00048545439494773746,\n",
              " -0.006348122842609882,\n",
              " 0.022322632372379303,\n",
              " 0.011121619492769241,\n",
              " -0.013033664785325527,\n",
              " -0.009500681422650814,\n",
              " 0.03048686683177948,\n",
              " 0.01565363071858883,\n",
              " 0.013516638427972794,\n",
              " -0.005742751993238926,\n",
              " -0.028793152421712875,\n",
              " -0.0003812512441072613,\n",
              " 0.015018487349152565,\n",
              " -0.014978790655732155,\n",
              " 0.021674256771802902,\n",
              " 0.004849581979215145,\n",
              " -0.007185055874288082,\n",
              " -0.001849192543886602,\n",
              " 0.015759486705064774,\n",
              " -0.034985799342393875,\n",
              " -0.03607083484530449,\n",
              " -0.023579686880111694,\n",
              " 0.030089903622865677,\n",
              " 0.014065772294998169,\n",
              " 0.018723487854003906,\n",
              " -0.030301617458462715,\n",
              " -0.018247131258249283,\n",
              " -0.01923954300582409,\n",
              " -0.024916132912039757,\n",
              " 0.011624441482126713,\n",
              " -0.0016531914006918669,\n",
              " -0.0009733898332342505,\n",
              " 0.010671726427972317,\n",
              " -0.009302199818193913,\n",
              " -0.005269702523946762,\n",
              " -0.6368367671966553,\n",
              " -0.04017280042171478,\n",
              " -0.020774470642209053,\n",
              " -0.008250243961811066,\n",
              " 0.015521309338510036,\n",
              " 0.010003503412008286,\n",
              " -0.004144970327615738,\n",
              " 0.016288774088025093,\n",
              " -0.01243160292506218,\n",
              " 0.02425452694296837,\n",
              " -0.0030665502417832613,\n",
              " 0.007462931331247091,\n",
              " 0.01728118397295475,\n",
              " -0.010221834294497967,\n",
              " 0.0018161121988669038,\n",
              " -0.0020989493932574987,\n",
              " 0.012663165107369423,\n",
              " 0.002479373710229993,\n",
              " -0.0011487158481031656,\n",
              " 0.002404942875728011,\n",
              " -0.02437361516058445,\n",
              " 0.01192216482013464,\n",
              " -0.0027059740386903286,\n",
              " -0.027893366292119026,\n",
              " 0.009242654778063297,\n",
              " 0.02363261580467224,\n",
              " 0.01874995231628418,\n",
              " -0.02852850966155529,\n",
              " -0.004158202093094587,\n",
              " 0.00011309351248200983,\n",
              " -0.031810082495212555,\n",
              " 0.0021882664877921343,\n",
              " 0.029534153640270233,\n",
              " 0.0104136997833848,\n",
              " 0.0407550148665905,\n",
              " -0.004426153376698494,\n",
              " -0.018432380631566048,\n",
              " 0.04202530160546303,\n",
              " 0.010506325401365757,\n",
              " 0.04247519373893738,\n",
              " -0.008858922868967056,\n",
              " -0.007919440045952797,\n",
              " 0.000740586721803993,\n",
              " 0.011339950375258923,\n",
              " 0.0025620744563639164,\n",
              " -0.024545634165406227,\n",
              " 0.009798404760658741,\n",
              " -0.0036520727444440126,\n",
              " 0.0066491542384028435,\n",
              " -0.012927807867527008,\n",
              " 1.4899087545927614e-05,\n",
              " 0.012411754578351974,\n",
              " -0.016606345772743225,\n",
              " -0.00022784103930462152,\n",
              " 0.005951158236712217,\n",
              " -0.019940845668315887,\n",
              " 0.012458066456019878,\n",
              " 0.018405916169285774,\n",
              " -0.00775403855368495,\n",
              " 0.013483557850122452,\n",
              " -0.0006388646434061229,\n",
              " 0.0048131938092410564,\n",
              " -0.020390739664435387,\n",
              " -0.01923954300582409,\n",
              " 0.004998443648219109,\n",
              " 0.026345204561948776,\n",
              " -0.009282351471483707,\n",
              " 0.011406110599637032,\n",
              " 0.03808211907744408,\n",
              " -0.012914575636386871,\n",
              " 0.021899204701185226,\n",
              " 0.0412578359246254,\n",
              " -0.022362329065799713,\n",
              " 0.001943471608683467,\n",
              " 0.007582020480185747,\n",
              " 7.205317524494603e-05,\n",
              " 0.027522865682840347,\n",
              " -0.006874100770801306,\n",
              " -0.0006421726429834962,\n",
              " -0.0005913116037845612,\n",
              " -0.011459039524197578,\n",
              " -0.007476163096725941,\n",
              " -0.019954077899456024,\n",
              " 0.0024578713346272707,\n",
              " 0.021634560078382492,\n",
              " -0.002633197233080864,\n",
              " -0.04797976464033127,\n",
              " 0.022097686305642128,\n",
              " 0.004078809637576342,\n",
              " -0.01116793230175972,\n",
              " -0.0023669004440307617,\n",
              " 0.003483362728729844,\n",
              " -0.020245185121893883,\n",
              " -0.0004300447762943804,\n",
              " -0.029931116849184036,\n",
              " 0.023222418501973152,\n",
              " -0.011908932588994503,\n",
              " -0.004072193522006273,\n",
              " 0.01324537955224514,\n",
              " -0.020165791735053062,\n",
              " -0.002853181678801775,\n",
              " -0.02799922414124012,\n",
              " 0.03736758604645729,\n",
              " -0.004664332140237093,\n",
              " 0.021105274558067322,\n",
              " -0.00805176142603159,\n",
              " 0.016804827377200127,\n",
              " 0.00021522914175875485,\n",
              " 0.03011636808514595,\n",
              " -0.005309399217367172,\n",
              " -0.015415451489388943,\n",
              " 0.012034637853503227,\n",
              " 0.0023487061262130737,\n",
              " -0.005097684916108847,\n",
              " -0.003797626355662942,\n",
              " -0.03263047710061073,\n",
              " 0.017598755657672882,\n",
              " 0.009460985660552979,\n",
              " 0.02694065123796463,\n",
              " -0.020642150193452835,\n",
              " 0.0036454566288739443,\n",
              " 0.013562951236963272,\n",
              " 0.006103327963501215,\n",
              " -0.006229033228009939,\n",
              " 0.026437830179929733,\n",
              " 0.028263866901397705,\n",
              " -0.018154505640268326,\n",
              " -0.0201790239661932,\n",
              " -0.022031525149941444,\n",
              " 0.006186028942465782,\n",
              " -0.0072710649110376835,\n",
              " 0.0038373228162527084,\n",
              " 0.013629111461341381,\n",
              " -0.025855615735054016,\n",
              " 0.007595252711325884,\n",
              " -0.01239190623164177,\n",
              " 0.008005449548363686,\n",
              " -0.009566842578351498,\n",
              " 0.021131739020347595,\n",
              " -0.007065966725349426,\n",
              " -0.04178712144494057,\n",
              " 0.014700915664434433,\n",
              " 0.007926056161522865,\n",
              " 0.010810664854943752,\n",
              " -0.011088539846241474,\n",
              " -0.00856119953095913,\n",
              " -0.005018291994929314,\n",
              " -0.023976651951670647,\n",
              " -0.03525044023990631,\n",
              " 0.007198288105428219,\n",
              " 0.02621288411319256,\n",
              " -0.025538044050335884,\n",
              " 0.0022544271778315306,\n",
              " -0.01597120240330696,\n",
              " 0.016354933381080627,\n",
              " -0.0022494650911539793,\n",
              " 0.0029689630027860403,\n",
              " -0.018352989107370377,\n",
              " -3.411413126741536e-05,\n",
              " 0.002520723966881633,\n",
              " -0.02905779518187046,\n",
              " 0.043666087090969086,\n",
              " 0.0017019849037751555,\n",
              " 0.0110620753839612,\n",
              " -0.005091068800538778,\n",
              " -0.00756878824904561,\n",
              " 0.002982195233926177,\n",
              " 0.0228254534304142,\n",
              " 0.012299280613660812,\n",
              " -0.015111112035810947,\n",
              " 0.006473828107118607,\n",
              " -0.031439583748579025,\n",
              " -0.0057162875309586525,\n",
              " 0.033027440309524536,\n",
              " -0.0025587663985788822,\n",
              " 0.008978012017905712,\n",
              " -0.007529092021286488,\n",
              " -0.005646818783134222,\n",
              " 0.00969916395843029,\n",
              " -0.009328664280474186,\n",
              " -0.0006727720028720796,\n",
              " -0.014317183755338192,\n",
              " 0.011928780935704708,\n",
              " 0.016288774088025093,\n",
              " 0.013933450914919376,\n",
              " -0.014489201828837395,\n",
              " 0.00038042422966100276,\n",
              " 0.010956218466162682,\n",
              " -0.012517611496150494,\n",
              " 0.04625958576798439,\n",
              " -0.012312512844800949,\n",
              " 0.00031322974245995283,\n",
              " 0.003685153089463711,\n",
              " 0.021039113402366638,\n",
              " -0.004389764741063118,\n",
              " 0.006268729921430349,\n",
              " 0.020562756806612015,\n",
              " 0.028105080127716064,\n",
              " 0.02400311455130577,\n",
              " 0.024770580232143402,\n",
              " -0.01088344119489193,\n",
              " -0.0028482198249548674,\n",
              " 0.02979879640042782,\n",
              " -0.018247131258249283,\n",
              " 0.010856976732611656,\n",
              " -0.020562756806612015,\n",
              " 0.002686125924810767,\n",
              " -0.006219109054654837,\n",
              " 0.011293637566268444,\n",
              " -0.018935203552246094,\n",
              " 0.018974900245666504,\n",
              " -0.024069275707006454,\n",
              " -0.011108387261629105,\n",
              " -0.029295973479747772,\n",
              " 0.026146722957491875,\n",
              " 0.011948629282414913,\n",
              " -0.01606382615864277,\n",
              " 0.007701109629124403,\n",
              " -0.03419186919927597,\n",
              " 0.014700915664434433,\n",
              " -0.007793734781444073,\n",
              " 0.004561782814562321,\n",
              " 0.01230589672923088,\n",
              " -0.002087371191009879,\n",
              " -0.011326718144118786,\n",
              " -0.005650126840919256,\n",
              " 0.030539795756340027,\n",
              " 0.005928001832216978,\n",
              " 0.0006930337403900921,\n",
              " -0.03937887027859688,\n",
              " -0.011154700070619583,\n",
              " -0.0024727575946599245,\n",
              " 0.00011516103404574096,\n",
              " 0.0190278273075819,\n",
              " 0.024241294711828232,\n",
              " -0.005977622698992491,\n",
              " -0.00756878824904561,\n",
              " -0.009666083380579948,\n",
              " 0.04030512273311615,\n",
              " 0.021740417927503586,\n",
              " 0.015997666865587234,\n",
              " 0.002356976270675659,\n",
              " 0.02868729643523693,\n",
              " -0.01659311354160309,\n",
              " -0.00916987843811512,\n",
              " -0.01216695923358202,\n",
              " 0.02155516855418682,\n",
              " -0.004128430038690567,\n",
              " 0.007489395327866077,\n",
              " -0.010989298112690449,\n",
              " -0.0007401732727885246,\n",
              " 0.013278460130095482,\n",
              " -0.0017003309912979603,\n",
              " 0.009745476767420769,\n",
              " -0.0021402998827397823,\n",
              " -0.022428490221500397,\n",
              " 0.01069819089025259,\n",
              " 0.015124344266951084,\n",
              " -0.009004476480185986,\n",
              " 0.026186419650912285,\n",
              " 0.0015233509475365281,\n",
              " 0.002729130443185568,\n",
              " -0.002447947161272168,\n",
              " -0.004045729059726,\n",
              " -0.0006984092760831118,\n",
              " -0.015494844876229763,\n",
              " 0.007740806322544813,\n",
              " 0.0011636019917204976,\n",
              " -0.021475775167346,\n",
              " -0.018974900245666504,\n",
              " 0.008296556770801544,\n",
              " -0.0030218916945159435,\n",
              " -0.0038174744695425034,\n",
              " -0.03231290355324745,\n",
              " 0.011908932588994503,\n",
              " 0.007065966725349426,\n",
              " 0.025246936827898026,\n",
              " -0.016778362914919853,\n",
              " 0.003982876427471638,\n",
              " 0.005630278494209051,\n",
              " -0.025008758530020714,\n",
              " -0.041998837143182755,\n",
              " 0.02649075910449028,\n",
              " 0.02433391846716404,\n",
              " -0.007608484942466021,\n",
              " -0.004307063762098551,\n",
              " -0.005405332427471876,\n",
              " 0.001695368904620409,\n",
              " -0.009593307040631771,\n",
              " 0.004359992686659098,\n",
              " -0.004849581979215145,\n",
              " -0.01026814617216587,\n",
              " 0.002600116888061166,\n",
              " -0.02934890240430832,\n",
              " 0.01343062985688448,\n",
              " 0.008448726497590542,\n",
              " 0.027972759678959846,\n",
              " -0.028660831972956657,\n",
              " 0.006258805748075247,\n",
              " -0.008217163383960724,\n",
              " 0.0036322243977338076,\n",
              " -0.019464489072561264,\n",
              " -0.037314657121896744,\n",
              " -0.024598561227321625,\n",
              " 0.04446001350879669,\n",
              " 0.002634851261973381,\n",
              " -0.0038472467567771673,\n",
              " -0.01452889759093523,\n",
              " -0.00805176142603159,\n",
              " -0.02420159801840782,\n",
              " 0.007720957975834608,\n",
              " 0.007496011443436146,\n",
              " -0.03003697469830513,\n",
              " -0.004988519474864006,\n",
              " -0.022203544154763222,\n",
              " 0.010473244823515415,\n",
              " -0.01845884509384632,\n",
              " -0.0025339561980217695,\n",
              " 0.02315625734627247,\n",
              " -0.008151003159582615,\n",
              " -0.019901148974895477,\n",
              " -0.03305390477180481,\n",
              " -0.03464176133275032,\n",
              " -0.0010974411852657795,\n",
              " 0.12279433012008667,\n",
              " 0.006801323965191841,\n",
              " -0.010115976445376873,\n",
              " -0.007529092021286488,\n",
              " 0.004078809637576342,\n",
              " -0.03884958475828171,\n",
              " -0.013265227898955345,\n",
              " -0.03178361803293228,\n",
              " 0.02535279467701912,\n",
              " 0.014396576210856438,\n",
              " 0.022018292918801308,\n",
              " -0.0018177662277594209,\n",
              " 0.00674508698284626,\n",
              " 0.01392021868377924,\n",
              " 0.0024677955079823732,\n",
              " -0.0037943182978779078,\n",
              " 0.004588247276842594,\n",
              " -0.013589415699243546,\n",
              " 0.0017334113363176584,\n",
              " -0.020139329135417938,\n",
              " -0.01927923783659935,\n",
              " 0.005243238527327776,\n",
              " -0.01785016618669033,\n",
              " 0.03191594034433365,\n",
              " -0.012848415412008762,\n",
              " -0.02441331185400486,\n",
              " 0.003437050385400653,\n",
              " 0.0018855809466913342,\n",
              " 0.04268690571188927,\n",
              " -0.006143024191260338,\n",
              " 0.006764935329556465,\n",
              " -0.021475775167346,\n",
              " 0.03183654695749283,\n",
              " -0.002304047578945756,\n",
              " 0.009586690925061703,\n",
              " 0.0018607707461342216,\n",
              " -0.007965752854943275,\n",
              " -2.117918847943656e-05,\n",
              " 0.018273595720529556,\n",
              " -0.0037612379528582096,\n",
              " 0.003800934413447976,\n",
              " 0.01679159514605999,\n",
              " 0.020139329135417938,\n",
              " -0.009070636704564095,\n",
              " 0.00926911924034357,\n",
              " -0.019940845668315887,\n",
              " 0.0155080771073699,\n",
              " 0.000243140704696998,\n",
              " 0.021780114620923996,\n",
              " -0.039961084723472595,\n",
              " 0.017109166830778122,\n",
              " 0.0007170169847086072,\n",
              " 0.002920996630564332,\n",
              " 0.0032699943985790014,\n",
              " 0.0026282353792339563,\n",
              " 0.008422262035310268,\n",
              " 0.01773107796907425,\n",
              " 0.005316015332937241,\n",
              " -0.012616852298378944,\n",
              " 0.03268340229988098,\n",
              " -0.008362716995179653,\n",
              " -0.021290525794029236,\n",
              " 0.02531309798359871,\n",
              " -0.007793734781444073,\n",
              " 0.0006661559455096722,\n",
              " -0.040940262377262115,\n",
              " -0.015561005100607872,\n",
              " -0.03501226380467415,\n",
              " -0.001756567507982254,\n",
              " -0.015018487349152565,\n",
              " -0.004919050727039576,\n",
              " 0.012544075958430767,\n",
              " -0.0367589071393013,\n",
              " 0.006602841429412365,\n",
              " 0.028343260288238525,\n",
              " 0.02208445407450199,\n",
              " 0.008581047877669334,\n",
              " -0.008237011730670929,\n",
              " 0.0005714633734896779,\n",
              " -0.00015154943685047328,\n",
              " -0.012782254256308079,\n",
              " -0.006040475331246853,\n",
              " 0.024876436218619347,\n",
              " 0.00862074363976717,\n",
              " 0.0034602065570652485,\n",
              " 0.01992761343717575,\n",
              " 0.006606149487197399,\n",
              " 0.014065772294998169,\n",
              " 0.006457287818193436,\n",
              " 0.031280796974897385,\n",
              " 0.014237790368497372,\n",
              " 0.009666083380579948,\n",
              " 0.004273983649909496,\n",
              " -0.0385584756731987,\n",
              " 0.006678926292806864,\n",
              " 0.016553416848182678,\n",
              " -0.02784043736755848,\n",
              " 0.013033664785325527,\n",
              " -0.000683936639688909,\n",
              " -0.004995135590434074,\n",
              " 0.0025289941113442183,\n",
              " -0.032789260149002075,\n",
              " 0.001584549667313695,\n",
              " 0.0012438218109309673,\n",
              " -0.0027092820964753628,\n",
              " 0.0104136997833848,\n",
              " -0.00020654554828070104,\n",
              " 0.027284687384963036,\n",
              " -0.03231290355324745,\n",
              " -0.022772526368498802,\n",
              " 0.048350267112255096,\n",
              " -0.018472077324986458,\n",
              " 0.000475116801680997,\n",
              " 0.01916014961898327,\n",
              " 0.022812221199274063,\n",
              " 0.030142832547426224,\n",
              " 0.010757735930383205,\n",
              " 0.013589415699243546,\n",
              " -0.0037446976639330387,\n",
              " -0.012656548991799355,\n",
              " -0.02731115184724331,\n",
              " -0.02045689895749092,\n",
              " -0.0006707044667564332,\n",
              " 0.019596809521317482,\n",
              " -0.054304733872413635,\n",
              " 0.017492899671196938,\n",
              " -0.017373809590935707,\n",
              " -0.06356723606586456,\n",
              " -0.0027655188459903,\n",
              " 0.006642538122832775,\n",
              " -0.0015043297316879034,\n",
              " 0.00884569063782692,\n",
              " 0.00289949425496161,\n",
              " -0.023328276351094246,\n",
              " -0.024876436218619347,\n",
              " -0.014634755440056324,\n",
              " -0.004171434324234724,\n",
              " -0.002729130443185568,\n",
              " -0.0033163069747388363,\n",
              " 0.020245185121893883,\n",
              " 0.008223779499530792,\n",
              " -0.008329636417329311,\n",
              " -0.010976065881550312,\n",
              " -0.024320686236023903,\n",
              " -0.029640009626746178,\n",
              " -0.023037169128656387,\n",
              " -0.007780502550303936,\n",
              " -0.004561782814562321,\n",
              " 0.006966725457459688,\n",
              " 0.021422846242785454,\n",
              " 0.005769216455519199,\n",
              " -0.0019798600114881992,\n",
              " -0.014012844301760197,\n",
              " 0.019861454144120216,\n",
              " 0.01691068522632122,\n",
              " -0.05287566035985947,\n",
              " 0.0048561980947852135,\n",
              " 0.007892975583672523,\n",
              " 0.036044370383024216,\n",
              " 0.012279433198273182,\n",
              " 0.04845612496137619,\n",
              " 0.021833043545484543,\n",
              " 0.04197237268090248,\n",
              " -0.009176494553685188,\n",
              " -0.018286827951669693,\n",
              " 0.02180657908320427,\n",
              " -0.0059114620089530945,\n",
              " -0.005230006296187639,\n",
              " -0.009963806718587875,\n",
              " 0.0009915840346366167,\n",
              " 0.02265343628823757,\n",
              " 0.02784043736755848,\n",
              " 0.020721543580293655,\n",
              " 0.025154313072562218,\n",
              " 0.01626230962574482,\n",
              " 0.01581241562962532,\n",
              " 0.006652462296187878,\n",
              " 0.007456315215677023,\n",
              " -0.0011454077903181314,\n",
              " -0.03125433251261711,\n",
              " 0.010995914228260517,\n",
              " -0.0028366416227072477,\n",
              " -0.0033163069747388363,\n",
              " 0.015944737941026688,\n",
              " -0.017625220119953156,\n",
              " -0.003074820153415203,\n",
              " 0.01788986288011074,\n",
              " 0.01243160292506218,\n",
              " 0.0039795683696866035,\n",
              " -0.01657988131046295,\n",
              " 0.033556725829839706,\n",
              " -0.03638840466737747,\n",
              " 0.00922942254692316,\n",
              " -0.009348511695861816,\n",
              " 0.0015374100767076015,\n",
              " -0.028660831972956657,\n",
              " -0.007237984798848629,\n",
              " -0.0009047480998560786,\n",
              " -0.0014249369269236922,\n",
              " 0.017347345128655434,\n",
              " 7.417238521156833e-05,\n",
              " -0.006768243387341499,\n",
              " -0.00628527021035552,\n",
              " 0.009546994231641293,\n",
              " -0.012702861800789833,\n",
              " 0.011009146459400654,\n",
              " -0.003721541492268443,\n",
              " 0.0007769751828163862,\n",
              " 0.005398716311901808,\n",
              " 0.003483362728729844,\n",
              " -0.024122204631567,\n",
              " -0.010764352045953274,\n",
              " -0.01646079123020172,\n",
              " -0.010248297825455666,\n",
              " -0.0015878577250987291,\n",
              " 0.008746449835598469,\n",
              " 0.003174061421304941,\n",
              " 0.020364275202155113,\n",
              " -0.03024868853390217,\n",
              " -0.027681652456521988,\n",
              " -0.009533762000501156,\n",
              " -0.024519169703125954,\n",
              " 0.03247169032692909,\n",
              " 0.011048843152821064,\n",
              " 0.015561005100607872,\n",
              " -0.0018723488319665194,\n",
              " -0.015561005100607872,\n",
              " -0.0056368946097791195,\n",
              " 0.013476941734552383,\n",
              " 0.015799183398485184,\n",
              " 0.004204514902085066,\n",
              " 0.005074528511613607,\n",
              " -0.00458493921905756,\n",
              " -0.0011156353866681457,\n",
              " -0.02897840365767479,\n",
              " -0.010486477054655552,\n",
              " 0.0006810420891270041,\n",
              " -0.001192547264508903,\n",
              " -0.012080950662493706,\n",
              " 0.015124344266951084,\n",
              " 0.0004949650028720498,\n",
              " -0.0031624832190573215,\n",
              " 0.0007157764630392194,\n",
              " -0.029481224715709686,\n",
              " -0.005428488366305828,\n",
              " 0.022957775741815567,\n",
              " 0.0010478206677362323,\n",
              " 0.006248881574720144,\n",
              " 0.003929947968572378,\n",
              " -0.025326330214738846,\n",
              " -0.03810858353972435,\n",
              " 0.015799183398485184,\n",
              " 0.0206289179623127,\n",
              " 0.008091458119452,\n",
              " 0.026226116344332695,\n",
              " -0.018564702942967415,\n",
              " 0.022521113976836205,\n",
              " -0.007218136452138424,\n",
              " 0.012993969023227692,\n",
              " 0.0055575016885995865,\n",
              " -0.021449310705065727,\n",
              " 0.007185055874288082,\n",
              " -0.020390739664435387,\n",
              " 0.031042618677020073,\n",
              " -0.013192450627684593,\n",
              " -0.0201790239661932,\n",
              " -0.021819811314344406,\n",
              " -0.00279198307543993,\n",
              " 0.00615294836461544,\n",
              " 0.02192566730082035,\n",
              " 0.010393851436674595,\n",
              " -0.0305662602186203,\n",
              " -0.013576183468103409,\n",
              " 0.029454760253429413,\n",
              " 0.0020642150193452835,\n",
              " 0.020933257415890694,\n",
              " 0.014767076820135117,\n",
              " -0.009355127811431885,\n",
              " -0.00038745382335036993,\n",
              " -0.0031922555062919855,\n",
              " 0.034668225795030594,\n",
              " 0.01845884509384632,\n",
              " 0.02261373959481716,\n",
              " 0.014171630144119263,\n",
              " -0.007482779212296009,\n",
              " -0.013655575923621655,\n",
              " -0.013589415699243546,\n",
              " 0.0009419635171070695,\n",
              " -0.014171630144119263,\n",
              " -0.02823740243911743,\n",
              " -0.016804827377200127,\n",
              " -0.036044370383024216,\n",
              " 0.011227477341890335,\n",
              " 0.012888111174106598,\n",
              " -0.013027048669755459,\n",
              " 0.023579686880111694,\n",
              " 0.005603814497590065,\n",
              " 0.013576183468103409,\n",
              " -0.03040747530758381,\n",
              " 0.015494844876229763,\n",
              " -0.007707725744694471,\n",
              " 0.011227477341890335,\n",
              " -0.019834989681839943,\n",
              " -0.0028664139099419117,\n",
              " 0.004833041690289974,\n",
              " -0.007687877397984266,\n",
              " 0.025908544659614563,\n",
              " -0.007919440045952797,\n",
              " -0.03194240480661392,\n",
              " -0.0019517417531460524,\n",
              " 0.03207472339272499,\n",
              " -0.021674256771802902,\n",
              " 7.510277646360919e-05,\n",
              " -0.022971007972955704,\n",
              " 0.01814127340912819,\n",
              " -0.006023935042321682,\n",
              " 0.01845884509384632,\n",
              " -0.02510138414800167,\n",
              " 0.002633197233080864,\n",
              " 0.019107220694422722,\n",
              " -0.003860478987917304,\n",
              " -0.005994162987917662,\n",
              " 0.009771941229701042,\n",
              " -0.015018487349152565,\n",
              " -0.006450671702623367,\n",
              " 0.02498229406774044,\n",
              " 0.013867290690541267,\n",
              " 0.014515665359795094,\n",
              " -0.035594478249549866,\n",
              " -0.0033493873197585344,\n",
              " 0.012967504560947418,\n",
              " 0.025260169059038162,\n",
              " -0.0022014984861016273,\n",
              " -0.01833975687623024,\n",
              " -0.011842772364616394,\n",
              " -0.02380463294684887,\n",
              " -0.01403930876404047,\n",
              " 0.007720957975834608,\n",
              " -0.010764352045953274,\n",
              " -0.008938315324485302,\n",
              " -0.00794590450823307,\n",
              " 0.021502239629626274,\n",
              " 0.010737887583673,\n",
              " 0.0021882664877921343,\n",
              " -0.00615294836461544,\n",
              " 0.0002049949107458815,\n",
              " -0.007277681026607752,\n",
              " 0.0034866707865148783,\n",
              " -0.02253434620797634,\n",
              " -0.015256665647029877,\n",
              " 0.012894727289676666,\n",
              " 0.030963225290179253,\n",
              " 0.005620354786515236,\n",
              " -0.027284687384963036,\n",
              " -0.01972913183271885,\n",
              " -0.00646059587597847,\n",
              " -0.039061300456523895,\n",
              " 0.00696010934188962,\n",
              " 0.004661024082452059,\n",
              " 0.0014133587246760726,\n",
              " 0.022851917892694473,\n",
              " -0.03487994149327278,\n",
              " -0.008911850862205029,\n",
              " 0.02543218806385994,\n",
              " -0.0015299670631065965,\n",
              " 0.006609457544982433,\n",
              " -0.009077252820134163,\n",
              " -0.0037546218372881413,\n",
              " -0.006589609198272228,\n",
              " -0.0007149494485929608,\n",
              " 0.010572485625743866,\n",
              " 0.02266666851937771,\n",
              " -0.010201985947787762,\n",
              " 0.005630278494209051,\n",
              " -0.015547772869467735,\n",
              " -0.023288579657673836,\n",
              " 0.010248297825455666,\n",
              " -0.009427905082702637,\n",
              " -0.017016541212797165,\n",
              " -0.0023453980684280396,\n",
              " -0.019782060757279396,\n",
              " -0.011955245397984982,\n",
              " 0.02615995518863201,\n",
              " -0.002275929320603609,\n",
              " -0.005226698238402605,\n",
              " 0.011373030953109264,\n",
              " 0.00020468478032853454,\n",
              " -0.008997860364615917,\n",
              " 0.002041058847680688,\n",
              " -0.014542129822075367,\n",
              " -0.007601868826895952,\n",
              " -0.0009535416029393673,\n",
              " 0.02261373959481716,\n",
              " 0.02449270524084568,\n",
              " -0.012147110886871815,\n",
              " -0.021012650802731514,\n",
              " 0.011511968448758125,\n",
              " -0.02237556129693985,\n",
              " 0.022057989612221718,\n",
              " -0.026636311784386635,\n",
              " 0.007654797285795212,\n",
              " 0.015203737653791904,\n",
              " 0.012484530918300152,\n",
              " 0.0068145557306706905,\n",
              " 0.0038836351595818996,\n",
              " 0.05073205381631851,\n",
              " -0.014687683433294296,\n",
              " -0.003986184485256672,\n",
              " -0.00021295486658345908,\n",
              " -0.016407862305641174,\n",
              " 0.012987352907657623,\n",
              " -0.0036752289161086082,\n",
              " 0.011902316473424435,\n",
              " -0.03556801378726959,\n",
              " -0.006635922007262707,\n",
              " 0.000848511466756463,\n",
              " -0.02323565073311329,\n",
              " -0.0011834502220153809,\n",
              " 0.016275541856884956,\n",
              " 0.009216190315783024,\n",
              " -0.02653045579791069,\n",
              " -0.007641565054655075,\n",
              " -0.01810157671570778,\n",
              " 0.005438412539660931,\n",
              " -0.018551470711827278,\n",
              " -0.016659272834658623,\n",
              " 0.00699980603531003,\n",
              " -0.0003514789277687669,\n",
              " -0.0049554393626749516,\n",
              " -0.003698385087773204,\n",
              " -0.006103327963501215,\n",
              " 0.0015018486883491278,\n",
              " -0.0035164430737495422,\n",
              " 0.017545826733112335,\n",
              " -0.0016134949401021004,\n",
              " 0.014912630431354046,\n",
              " 0.24050751328468323,\n",
              " 0.0029077643994241953,\n",
              " -0.007515859790146351,\n",
              " 0.015547772869467735,\n",
              " -0.011545049026608467,\n",
              " 0.022362329065799713,\n",
              " 0.01841914840042591,\n",
              " 0.02180657908320427,\n",
              " 0.0130601292476058,\n",
              " 0.003011967521160841,\n",
              " -0.024280989542603493,\n",
              " 0.0040589612908661366,\n",
              " -0.013906986452639103,\n",
              " 0.010764352045953274,\n",
              " -0.015005255118012428,\n",
              " -0.011280405335128307,\n",
              " -0.014872933737933636,\n",
              " -0.031889475882053375,\n",
              " -0.0018955051200464368,\n",
              " -0.04363962262868881,\n",
              " 0.014661218971014023,\n",
              " 0.009150030091404915,\n",
              " 0.005719595588743687,\n",
              " -0.00605370756238699,\n",
              " 0.034006617963314056,\n",
              " -0.0023420900106430054,\n",
              " 0.006073555443435907,\n",
              " -0.00252237799577415,\n",
              " 0.013761432841420174,\n",
              " -0.0018128041410818696,\n",
              " 0.005785756278783083,\n",
              " -0.005957774352282286,\n",
              " -0.018035417422652245,\n",
              " -0.00307647418230772,\n",
              " 0.0104136997833848,\n",
              " 0.005587274208664894,\n",
              " -0.010016735643148422,\n",
              " 0.020139329135417938,\n",
              " 0.012325745075941086,\n",
              " -0.015825647860765457,\n",
              " 0.011842772364616394,\n",
              " -0.016698969528079033,\n",
              " -0.009996887296438217,\n",
              " 0.0003560274781193584,\n",
              " -0.010016735643148422,\n",
              " 0.00454524252563715,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the most relevant parts of the video transcript to the query\n",
        "df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, prompt_embedding))\n",
        "results = (df.sort_values(\"similarity\", ascending=False)).head(3)\n",
        "# results = results.set_index(['id'])"
      ],
      "metadata": {
        "id": "dnmdUaU_sxyQ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(results)"
      ],
      "metadata": {
        "id": "ngCtoQ29s1o_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "845f6e68-d867-40c9-d53f-86306b04ab61"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  text  n_tokens  \\\n",
              "78   and stop.” “Yes, I’ve heard about that,” said ...      1301   \n",
              "68   Indian; yelling, laughing, chasing boys, jumpi...      1242   \n",
              "172  laugh at this pleasant joke. But the silence w...      1242   \n",
              "\n",
              "                                             embedding  similarity  \n",
              "78   [0.002508266130462289, -0.0182208102196455, 0....    0.860773  \n",
              "68   [-0.026282379403710365, -0.02262263558804989, ...    0.858479  \n",
              "172  [-0.006196146830916405, -0.011552021838724613,...    0.858168  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d798507a-1a14-45c5-a5f5-3047440ec269\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embedding</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>and stop.” “Yes, I’ve heard about that,” said ...</td>\n",
              "      <td>1301</td>\n",
              "      <td>[0.002508266130462289, -0.0182208102196455, 0....</td>\n",
              "      <td>0.860773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Indian; yelling, laughing, chasing boys, jumpi...</td>\n",
              "      <td>1242</td>\n",
              "      <td>[-0.026282379403710365, -0.02262263558804989, ...</td>\n",
              "      <td>0.858479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>laugh at this pleasant joke. But the silence w...</td>\n",
              "      <td>1242</td>\n",
              "      <td>[-0.006196146830916405, -0.011552021838724613,...</td>\n",
              "      <td>0.858168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d798507a-1a14-45c5-a5f5-3047440ec269')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d798507a-1a14-45c5-a5f5-3047440ec269 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d798507a-1a14-45c5-a5f5-3047440ec269');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[\"text\"].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "c4FmWbM1kGlA",
        "outputId": "2f15102e-da73-4fa0-a920-e25e06ed9049"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and stop.” “Yes, I’ve heard about that,” said Joe. “I wonder what makes the bread do that.” “Oh, it ain’t the bread, so much,” said Tom; “I reckon it’s mostly what they _say_ over it before they start it out.” “But they don’t say anything over it,” said Huck. “I’ve seen ’em and they don’t.” “Well, that’s funny,” said Tom. “But maybe they say it to themselves. Of _course_ they do. Anybody might know that.” The other boys agreed that there was reason in what Tom said, because an ignorant lump of bread, uninstructed by an incantation, could not be expected to act very intelligently when set upon an errand of such gravity. “By jings, I wish I was over there, now,” said Joe. “I do too” said Huck “I’d give heaps to know who it is.” The boys still listened and watched. Presently a revealing thought flashed through Tom’s mind, and he exclaimed: “Boys, I know who’s drownded—it’s us!” They felt like heroes in an instant. Here was a gorgeous triumph; they were missed; they were mourned; hearts were breaking on their account; tears were being shed; accusing memories of unkindness to these poor lost lads were rising up, and unavailing regrets and remorse were being indulged; and best of all, the departed were the talk of the whole town, and the envy of all the boys, as far as this dazzling notoriety was concerned. This was fine. It was worth while to be a pirate, after all. As twilight drew on, the ferryboat went back to her accustomed business and the skiffs disappeared. The pirates returned to camp. They were jubilant with vanity over their new grandeur and the illustrious trouble they were making. They caught fish, cooked supper and ate it, and then fell to guessing at what the village was thinking and saying about them; and the pictures they drew of the public distress on their account were gratifying to look upon—from their point of view. But when the shadows of night closed them in, they gradually ceased to talk, and sat gazing into the fire, with their minds evidently wandering elsewhere. The excitement was gone, now, and Tom and Joe could not keep back thoughts of certain persons at home who were not enjoying this fine frolic as much as they were. Misgivings came; they grew troubled and unhappy; a sigh or two escaped, unawares. By and by Joe timidly ventured upon a roundabout “feeler” as to how the others might look upon a return to civilization—not right now, but— Tom withered him with derision! Huck, being uncommitted as yet, joined in with Tom, and the waverer quickly “explained,” and was glad to get out of the scrape with as little taint of chicken-hearted home-sickness clinging to his garments as he could. Mutiny was effectually laid to rest for the moment. As the night deepened, Huck began to nod, and presently to snore. Joe followed next. Tom lay upon his elbow motionless, for some time, watching the two intently. At last he got up cautiously, on his knees, and went searching among the grass and the flickering reflections flung by the campfire. He picked up and inspected several large semi-cylinders of the thin white bark of a sycamore, and finally chose two which seemed to suit him. Then he knelt by the fire and painfully wrote something upon each of these with his “red keel”; one he rolled up and put in his jacket pocket, and the other he put in Joe’s hat and removed it to a little distance from the owner. And he also put into the hat certain schoolboy treasures of almost inestimable value—among them a lump of chalk, an India-rubber ball, three fishhooks, and one of that kind of marbles known as a “sure ’nough crystal.” Then he tiptoed his way cautiously among the trees till he felt that he was out of hearing, and straightway broke into a keen run in the direction of the sandbar. CHAPTER XV A few minutes later Tom was in the shoal water of the bar, wading toward the Illinois shore. Before the depth reached his middle he was halfway over; the current would permit no more wading, now, so he struck out confidently to swim the remaining hundred yards. He swam quartering upstream, but still was swept downward rather faster than he had expected. However, he reached the shore finally, and drifted along till he found a low place and drew himself out. He put his hand on his jacket pocket, found his piece of bark safe, and then struck through the woods, following the shore, with streaming garments. Shortly before ten o’clock he came out into an open place opposite the village, and saw the ferryboat lying in the shadow of the trees and the high bank. Everything was quiet under the blinking stars. He crept down the bank, watching with all his eyes, slipped into the water, swam three or four strokes and climbed into the skiff that did “yawl” duty at the boat’s stern. He laid himself down under the thwarts and waited, panting. Presently the cracked bell tapped and a voice gave the order to “cast off.” A minute or two later the skiff’s head was standing high up, against the boat’s swell, and the voyage was begun. Tom felt happy in his success, for he knew it was the boat’s last trip for the night. At the end of a long twelve or fifteen minutes the wheels stopped, and Tom slipped overboard and swam ashore in the dusk, landing fifty yards downstream, out of danger of possible stragglers. He flew along unfrequented alleys, and shortly found himself at his aunt’s back fence. He climbed over, approached the “ell,” and looked in at the sitting-room window, for a light was burning there. There sat Aunt Polly, Sid, Mary, and Joe Harper’s mother, grouped together, talking. They were by the bed, and the bed was between them and the door. Tom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example token count from the OpenAI API\n",
        "limit = 2500\n",
        "\n",
        "def retrieve(results):\n",
        "\n",
        "    # build our prompt with the retrieved contexts included\n",
        "    prompt_start = (\n",
        "        \"Answer the question based on the context below.\\n\\n\"+\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "\n",
        "    prompt_end = (\n",
        "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    prompt = prompt_start + \"\\n\\n---\\n\\n\".join(results[\"text\"]) + prompt_end\n",
        "    # contexts = [[text] for text in results['text'] ]\n",
        "    # print (contexts)\n",
        "    # append contexts until hitting limit\n",
        "    \n",
        "    # for i in range(1, len(results)):\n",
        "        # print (results[\"text\"].iloc[:i])\n",
        "        # print (len(\"\\n\\n---\\n\\n\".join(results[\"text\"].iloc[:i])))\n",
        "        # if len(\"\\n\\n---\\n\\n\".join(results[\"text\"].iloc[:i])) >= limit:\n",
        "        #     prompt = (\n",
        "        #         prompt_start +\n",
        "        #         \"\\n\\n---\\n\\n\".join(results[\"text\"].iloc[:i-1]) +\n",
        "        #         prompt_end\n",
        "        #     )\n",
        "        #     print(\"here\")\n",
        "        #     break\n",
        "        # elif i == len(results)-1:\n",
        "        #     prompt = (\n",
        "        #         prompt_start +\n",
        "        #         \"\\n\\n---\\n\\n\".join(results[\"text\"].iloc[i]) +\n",
        "        #         prompt_end\n",
        "        #     )\n",
        "        #     print(\"no here\")\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "DtYqNaMskIP3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first we retrieve relevant items from Pinecone\n",
        "query_with_contexts = retrieve(results, prompt)\n",
        "query_with_contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "JNhgYeuHL4ob",
        "outputId": "7182b62a-d86f-44bc-b987-c864f2c89268"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer the question based on the context below.\\n\\nContext:\\nand stop.” “Yes, I’ve heard about that,” said Joe. “I wonder what makes the bread do that.” “Oh, it ain’t the bread, so much,” said Tom; “I reckon it’s mostly what they _say_ over it before they start it out.” “But they don’t say anything over it,” said Huck. “I’ve seen ’em and they don’t.” “Well, that’s funny,” said Tom. “But maybe they say it to themselves. Of _course_ they do. Anybody might know that.” The other boys agreed that there was reason in what Tom said, because an ignorant lump of bread, uninstructed by an incantation, could not be expected to act very intelligently when set upon an errand of such gravity. “By jings, I wish I was over there, now,” said Joe. “I do too” said Huck “I’d give heaps to know who it is.” The boys still listened and watched. Presently a revealing thought flashed through Tom’s mind, and he exclaimed: “Boys, I know who’s drownded—it’s us!” They felt like heroes in an instant. Here was a gorgeous triumph; they were missed; they were mourned; hearts were breaking on their account; tears were being shed; accusing memories of unkindness to these poor lost lads were rising up, and unavailing regrets and remorse were being indulged; and best of all, the departed were the talk of the whole town, and the envy of all the boys, as far as this dazzling notoriety was concerned. This was fine. It was worth while to be a pirate, after all. As twilight drew on, the ferryboat went back to her accustomed business and the skiffs disappeared. The pirates returned to camp. They were jubilant with vanity over their new grandeur and the illustrious trouble they were making. They caught fish, cooked supper and ate it, and then fell to guessing at what the village was thinking and saying about them; and the pictures they drew of the public distress on their account were gratifying to look upon—from their point of view. But when the shadows of night closed them in, they gradually ceased to talk, and sat gazing into the fire, with their minds evidently wandering elsewhere. The excitement was gone, now, and Tom and Joe could not keep back thoughts of certain persons at home who were not enjoying this fine frolic as much as they were. Misgivings came; they grew troubled and unhappy; a sigh or two escaped, unawares. By and by Joe timidly ventured upon a roundabout “feeler” as to how the others might look upon a return to civilization—not right now, but— Tom withered him with derision! Huck, being uncommitted as yet, joined in with Tom, and the waverer quickly “explained,” and was glad to get out of the scrape with as little taint of chicken-hearted home-sickness clinging to his garments as he could. Mutiny was effectually laid to rest for the moment. As the night deepened, Huck began to nod, and presently to snore. Joe followed next. Tom lay upon his elbow motionless, for some time, watching the two intently. At last he got up cautiously, on his knees, and went searching among the grass and the flickering reflections flung by the campfire. He picked up and inspected several large semi-cylinders of the thin white bark of a sycamore, and finally chose two which seemed to suit him. Then he knelt by the fire and painfully wrote something upon each of these with his “red keel”; one he rolled up and put in his jacket pocket, and the other he put in Joe’s hat and removed it to a little distance from the owner. And he also put into the hat certain schoolboy treasures of almost inestimable value—among them a lump of chalk, an India-rubber ball, three fishhooks, and one of that kind of marbles known as a “sure ’nough crystal.” Then he tiptoed his way cautiously among the trees till he felt that he was out of hearing, and straightway broke into a keen run in the direction of the sandbar. CHAPTER XV A few minutes later Tom was in the shoal water of the bar, wading toward the Illinois shore. Before the depth reached his middle he was halfway over; the current would permit no more wading, now, so he struck out confidently to swim the remaining hundred yards. He swam quartering upstream, but still was swept downward rather faster than he had expected. However, he reached the shore finally, and drifted along till he found a low place and drew himself out. He put his hand on his jacket pocket, found his piece of bark safe, and then struck through the woods, following the shore, with streaming garments. Shortly before ten o’clock he came out into an open place opposite the village, and saw the ferryboat lying in the shadow of the trees and the high bank. Everything was quiet under the blinking stars. He crept down the bank, watching with all his eyes, slipped into the water, swam three or four strokes and climbed into the skiff that did “yawl” duty at the boat’s stern. He laid himself down under the thwarts and waited, panting. Presently the cracked bell tapped and a voice gave the order to “cast off.” A minute or two later the skiff’s head was standing high up, against the boat’s swell, and the voyage was begun. Tom felt happy in his success, for he knew it was the boat’s last trip for the night. At the end of a long twelve or fifteen minutes the wheels stopped, and Tom slipped overboard and swam ashore in the dusk, landing fifty yards downstream, out of danger of possible stragglers. He flew along unfrequented alleys, and shortly found himself at his aunt’s back fence. He climbed over, approached the “ell,” and looked in at the sitting-room window, for a light was burning there. There sat Aunt Polly, Sid, Mary, and Joe Harper’s mother, grouped together, talking. They were by the bed, and the bed was between them and the door. Tom\\n\\n---\\n\\nIndian; yelling, laughing, chasing boys, jumping over the fence at risk of life and limb, throwing handsprings, standing on his head—doing all the heroic things he could conceive of, and keeping a furtive eye out, all the while, to see if Becky Thatcher was noticing. But she seemed to be unconscious of it all; she never looked. Could it be possible that she was not aware that he was there? He carried his exploits to her immediate vicinity; came war-whooping around, snatched a boy’s cap, hurled it to the roof of the schoolhouse, broke through a group of boys, tumbling them in every direction, and fell sprawling, himself, under Becky’s nose, almost upsetting her—and she turned, with her nose in the air, and he heard her say: “Mf! some people think they’re mighty smart—always showing off!” Tom’s cheeks burned. He gathered himself up and sneaked off, crushed and crestfallen. CHAPTER XIII TOM’S mind was made up now. He was gloomy and desperate. He was a forsaken, friendless boy, he said; nobody loved him; when they found out what they had driven him to, perhaps they would be sorry; he had tried to do right and get along, but they would not let him; since nothing would do them but to be rid of him, let it be so; and let them blame _him_ for the consequences—why shouldn’t they? What right had the friendless to complain? Yes, they had forced him to it at last: he would lead a life of crime. There was no choice. By this time he was far down Meadow Lane, and the bell for school to “take up” tinkled faintly upon his ear. He sobbed, now, to think he should never, never hear that old familiar sound any more—it was very hard, but it was forced on him; since he was driven out into the cold world, he must submit—but he forgave them. Then the sobs came thick and fast. Just at this point he met his soul’s sworn comrade, Joe Harper—hard-eyed, and with evidently a great and dismal purpose in his heart. Plainly here were “two souls with but a single thought.” Tom, wiping his eyes with his sleeve, began to blubber out something about a resolution to escape from hard usage and lack of sympathy at home by roaming abroad into the great world never to return; and ended by hoping that Joe would not forget him. But it transpired that this was a request which Joe had just been going to make of Tom, and had come to hunt him up for that purpose. His mother had whipped him for drinking some cream which he had never tasted and knew nothing about; it was plain that she was tired of him and wished him to go; if she felt that way, there was nothing for him to do but succumb; he hoped she would be happy, and never regret having driven her poor boy out into the unfeeling world to suffer and die. As the two boys walked sorrowing along, they made a new compact to stand by each other and be brothers and never separate till death relieved them of their troubles. Then they began to lay their plans. Joe was for being a hermit, and living on crusts in a remote cave, and dying, some time, of cold and want and grief; but after listening to Tom, he conceded that there were some conspicuous advantages about a life of crime, and so he consented to be a pirate. Three miles below St. Petersburg, at a point where the Mississippi River was a trifle over a mile wide, there was a long, narrow, wooded island, with a shallow bar at the head of it, and this offered well as a rendezvous. It was not inhabited; it lay far over toward the further shore, abreast a dense and almost wholly unpeopled forest. So Jackson’s Island was chosen. Who were to be the subjects of their piracies was a matter that did not occur to them. Then they hunted up Huckleberry Finn, and he joined them promptly, for all careers were one to him; he was indifferent. They presently separated to meet at a lonely spot on the river-bank two miles above the village at the favorite hour—which was midnight. There was a small log raft there which they meant to capture. Each would bring hooks and lines, and such provision as he could steal in the most dark and mysterious way—as became outlaws. And before the afternoon was done, they had all managed to enjoy the sweet glory of spreading the fact that pretty soon the town would “hear something.” All who got this vague hint were cautioned to “be mum and wait.” About midnight Tom arrived with a boiled ham and a few trifles, and stopped in a dense undergrowth on a small bluff overlooking the meeting-place. It was starlight, and very still. The mighty river lay like an ocean at rest. Tom listened a moment, but no sound disturbed the quiet. Then he gave a low, distinct whistle. It was answered from under the bluff. Tom whistled twice more; these signals were answered in the same way. Then a guarded voice said: “Who goes there?” “Tom Sawyer, the Black Avenger of the Spanish Main. Name your names.” “Huck Finn the Red-Handed, and Joe Harper the Terror of the Seas.” Tom had furnished these titles, from his favorite literature. “’Tis well. Give the countersign.” Two hoarse whispers delivered the same awful word simultaneously to the brooding night: “_Blood_!” Then Tom tumbled his ham over the bluff and let himself down after it, tearing both skin and clothes to some extent in the effort. There was an easy, comfortable path along the shore under the bluff, but it lacked the advantages of difficulty and danger so valued by a pirate. The Terror of the Seas had brought a side of bacon, and had about worn himself out with getting it there. Finn the\\n\\n---\\n\\nlaugh at this pleasant joke. But the silence was a little awkward. Tom broke it: “Huck’s got money. Maybe you don’t believe it, but he’s got lots of it. Oh, you needn’t smile—I reckon I can show you. You just wait a minute.” Tom ran out of doors. The company looked at each other with a perplexed interest—and inquiringly at Huck, who was tongue-tied. “Sid, what ails Tom?” said Aunt Polly. “He—well, there ain’t ever any making of that boy out. I never—” Tom entered, struggling with the weight of his sacks, and Aunt Polly did not finish her sentence. Tom poured the mass of yellow coin upon the table and said: “There—what did I tell you? Half of it’s Huck’s and half of it’s mine!” The spectacle took the general breath away. All gazed, nobody spoke for a moment. Then there was a unanimous call for an explanation. Tom said he could furnish it, and he did. The tale was long, but brimful of interest. There was scarcely an interruption from any one to break the charm of its flow. When he had finished, Mr. Jones said: “I thought I had fixed up a little surprise for this occasion, but it don’t amount to anything now. This one makes it sing mighty small, I’m willing to allow.” The money was counted. The sum amounted to a little over twelve thousand dollars. It was more than any one present had ever seen at one time before, though several persons were there who were worth considerably more than that in property. CHAPTER XXXV THE reader may rest satisfied that Tom’s and Huck’s windfall made a mighty stir in the poor little village of St. Petersburg. So vast a sum, all in actual cash, seemed next to incredible. It was talked about, gloated over, glorified, until the reason of many of the citizens tottered under the strain of the unhealthy excitement. Every “haunted” house in St. Petersburg and the neighboring villages was dissected, plank by plank, and its foundations dug up and ransacked for hidden treasure—and not by boys, but men—pretty grave, unromantic men, too, some of them. Wherever Tom and Huck appeared they were courted, admired, stared at. The boys were not able to remember that their remarks had possessed weight before; but now their sayings were treasured and repeated; everything they did seemed somehow to be regarded as remarkable; they had evidently lost the power of doing and saying commonplace things; moreover, their past history was raked up and discovered to bear marks of conspicuous originality. The village paper published biographical sketches of the boys. The Widow Douglas put Huck’s money out at six per cent., and Judge Thatcher did the same with Tom’s at Aunt Polly’s request. Each lad had an income, now, that was simply prodigious—a dollar for every weekday in the year and half of the Sundays. It was just what the minister got—no, it was what he was promised—he generally couldn’t collect it. A dollar and a quarter a week would board, lodge, and school a boy in those old simple days—and clothe him and wash him, too, for that matter. Judge Thatcher had conceived a great opinion of Tom. He said that no commonplace boy would ever have got his daughter out of the cave. When Becky told her father, in strict confidence, how Tom had taken her whipping at school, the Judge was visibly moved; and when she pleaded grace for the mighty lie which Tom had told in order to shift that whipping from her shoulders to his own, the Judge said with a fine outburst that it was a noble, a generous, a magnanimous lie—a lie that was worthy to hold up its head and march down through history breast to breast with George Washington’s lauded Truth about the hatchet! Becky thought her father had never looked so tall and so superb as when he walked the floor and stamped his foot and said that. She went straight off and told Tom about it. Judge Thatcher hoped to see Tom a great lawyer or a great soldier some day. He said he meant to look to it that Tom should be admitted to the National Military Academy and afterward trained in the best law school in the country, in order that he might be ready for either career or both. Huck Finn’s wealth and the fact that he was now under the Widow Douglas’ protection introduced him into society—no, dragged him into it, hurled him into it—and his sufferings were almost more than he could bear. The widow’s servants kept him clean and neat, combed and brushed, and they bedded him nightly in unsympathetic sheets that had not one little spot or stain which he could press to his heart and know for a friend. He had to eat with a knife and fork; he had to use napkin, cup, and plate; he had to learn his book, he had to go to church; he had to talk so properly that speech was become insipid in his mouth; whithersoever he turned, the bars and shackles of civilization shut him in and bound him hand and foot. He bravely bore his miseries three weeks, and then one day turned up missing. For forty-eight hours the widow hunted for him everywhere in great distress. The public were profoundly concerned; they searched high and low, they dragged the river for his body. Early the third morning Tom Sawyer wisely went poking among some old empty hogsheads down behind the abandoned slaughter-house, and in one of them he found the refugee. Huck had slept there; he had just breakfasted upon some stolen odds and ends of food, and was lying off, now, in comfort, with his pipe. He was unkempt, uncombed, and clad in the same old ruin of rags that had made him picturesque in the days when he was free and happy. Tom routed him out, told him the trouble he had been causing,\\n\\nQuestion: How did Tom meet Huck for the first time ?\\nAnswer:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "\n",
        "query = \"How did Tom meet Huck for the first time ?\"\n",
        "prompt_start = (\"Answer the question based on the context below.\\n\\n\"+ \"Context:\\n\")\n",
        "prompt_end = (f\"\\n\\nQuestion: {query}\\nAnswer:\")\n",
        "prompt = prompt_start + \"\\n\\n---\\n\\n\".join(results[\"text\"]) + prompt_end\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8dXDp1ltNL91",
        "outputId": "6ef28769-2ba6-4959-cc77-61a0f216457c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The novel does not provide a clear answer to this question.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYI0GV9BV6GD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}